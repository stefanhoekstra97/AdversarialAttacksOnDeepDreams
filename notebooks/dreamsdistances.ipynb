{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import PIL\n",
    "from PIL import GifImagePlugin, Image, ImageDraw, ImageFont\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10, MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "from generate_dreams.render_engine import generate_dream\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "models = {}\n",
    "use_dataset:str = \"CIFAR\"\n",
    "# use_dataset:str = \"MNIST\"\n",
    "# \n",
    "_model_loc_list_cifar = {\n",
    "    \"basemodel\": './modelfolder/cifar_base.pkl',\n",
    "    # \"PGD5\": './modelfolder/cifar_pgd5.pkl',\n",
    "    # \"PGDDream-16itlr1e-3\": 'modelfolder/cifar_PGD_dream16_1e-3.pkl',\n",
    "    # \"CW20-0.1\": 'modelfolder/cifar_CW20.pkl'\n",
    "}\n",
    "\n",
    "_model_loc_list_mnist = {\n",
    "    \"basemodel\": './modelfolder/mnist_base.pkl',\n",
    "    # \"PGD5\": './modelfolder/mnist_pgd5.pkl',\n",
    "}\n",
    "\n",
    "if \"MNIST\" in use_dataset:\n",
    "    _model_loc_list = _model_loc_list_mnist\n",
    "else:\n",
    "    _model_loc_list = _model_loc_list_cifar\n",
    "\n",
    "for _modelname, _modelloc in _model_loc_list.items():\n",
    "    _model = torch.load(_modelloc, map_location=torch_device)\n",
    "    _model.eval()\n",
    "    models[_modelname] = _model\n",
    "\n",
    "\n",
    "# save_data = True\n",
    "save_data = False\n",
    "save_loc = 'imgs/test'\n",
    "save_suffix = '_tt'\n",
    "\n",
    "\n",
    "bsize = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "_transforms = transforms.Compose([transforms.ToTensor(),])\n",
    "_to_pil = transforms.ToPILImage()\n",
    "\n",
    "_CIFAR_data = CIFAR10(root='../../data/cifar/', train=True, download=True, transform=_transforms)\n",
    "cifar_dataloader = DataLoader(dataset=_CIFAR_data, batch_size=bsize, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "_MNIST_data = MNIST(root='../../data/mnist/', train=True, download=True, transform=_transforms)\n",
    "mnist_dataloader = DataLoader(dataset=_MNIST_data, batch_size=bsize, shuffle=False, num_workers=0)\n",
    "\n",
    "if \"MNIST\" in use_dataset:\n",
    "    dataloader = mnist_dataloader\n",
    "else:\n",
    "    dataloader = cifar_dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_b = next(iter(dataloader))\n",
    "# _x, _y = img_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_b = next(iter(dataloader))\n",
    "_x, _y = img_b\n",
    "\n",
    "_unique, _inverse = torch.unique(_y, return_inverse=True, dim=0)\n",
    "\n",
    "_perm = torch.arange(_inverse.size(0), dtype=_inverse.dtype, device=_inverse.device)\n",
    "\n",
    "_inverse, _perm = _inverse.flip([0]), _perm.flip([0])\n",
    "\n",
    "_first_class_idxs = _inverse.new_empty(_unique.size(0)).scatter_(0, _inverse, _perm)\n",
    "_dream_imgs = _x[_first_class_idxs]\n",
    "_dream_lbl = torch.arange(0, 10, 1, device=torch_device)\n",
    "\n",
    "boatimg, boatlbl = _dream_imgs[8].unsqueeze(0), _dream_lbl[8].unsqueeze(0)\n",
    "# boatimg, boatlbl = _dream_imgs[5].unsqueeze(0), _dream_lbl[5].unsqueeze(0)\n",
    "\n",
    "img_b = (boatimg, boatlbl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boatimg = _to_pil(boatimg)\n",
    "# with open(\"imgs/test/verboat.jpeg\", 'wb') as f:\n",
    "#     boatimg.save(fp=f, format=\"jpeg\", quality=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boatimg = _x[5]\n",
    "# boatimg = _to_pil(boatimg)\n",
    "# with open(\"imgs/5.jpeg\", 'wb') as f:\n",
    "#     boatimg.save(fp=f , format=\"jpeg\", quality=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if save_gif:\n",
    "#     pil_img_array[0].save(gif_save_loc + 'lr1e3_smooth_cat_pgd5.gif', format='GIF',\n",
    "#         append_images=pil_img_array[1:],\n",
    "#         duration=50,\n",
    "#         interlace=False,\n",
    "#         save_all=True,\n",
    "#         loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_lpdist(im1:torch.Tensor, im2:torch.Tensor, ord=2):\n",
    "    diff = torch.sub(im1, im2)\n",
    "    return torch.linalg.vector_norm(diff, ord=ord, dim=(-3, -2, -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(t1: torch.Tensor, t2: torch.Tensor, idx):\n",
    "    t1, t2 = t1.cpu().clone(), t2.cpu().clone()\n",
    "    diffs = torch.sub(t1, t2)\n",
    "    l2 = torch.linalg.vector_norm(diffs, ord=2, dim=(-3, -2, -1))\n",
    "    li = torch.linalg.vector_norm(diffs, ord=float('inf'), dim=(-3, -2, -1))\n",
    "    \n",
    "    avg_l2 = torch.mean(l2)\n",
    "    max_l2 = torch.max(l2)\n",
    "    min_l2 = torch.min(l2)\n",
    "\n",
    "    avg_li = torch.mean(li)\n",
    "    max_li = torch.max(li)\n",
    "    min_li = torch.min(li)\n",
    "\n",
    "    l2_std = torch.std(l2)\n",
    "    li_std = torch.std(li)\n",
    "\n",
    "    return {\n",
    "        \"idx\": idx,\n",
    "        \"shape\":l2.shape[0],\n",
    "        \"avg_l2\": avg_l2.item(),\n",
    "        \"max_l2\": max_l2.item(),\n",
    "        \"min_l2\": min_l2.item(),\n",
    "\n",
    "        \"avg_li\": avg_li.item(),\n",
    "        \"max_li\": max_li.item(),\n",
    "        \"min_li\": min_li.item(),\n",
    "\n",
    "        # \"l2_std\": l2_std.item(),\n",
    "        # \"li_std\": li_std.item(),\n",
    "       \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterlist = np.arange(0, 256, 32)\n",
    "iterlist = np.arange(0, 129, 1)\n",
    "# iterlist = np.arange(0, 6, 2)\n",
    "# iterlist = np.arange(0, 512, 64)\n",
    "\n",
    "origs, lbls = img_b\n",
    "origs = origs.detach().clone().to(torch_device)\n",
    "lbls = lbls.detach().clone().to(torch_device)\n",
    "\n",
    "lr =1e-1\n",
    "\n",
    "dreams = generate_dream(model=models[\"basemodel\"], batch=img_b, device=torch_device, opt_lr=lr, iterations=iterlist, parametrization=\"tanh\")\n",
    "statlist= []\n",
    "totablel2 = []\n",
    "totableli = []\n",
    "for idx, dream in enumerate(dreams):\n",
    "    stats = print_stats(origs, dream, idx)\n",
    "    statlist.append(stats)\n",
    "    totablel2.append(stats[\"avg_l2\"])\n",
    "    totableli.append(stats[\"avg_li\"])\n",
    "    # print(f\"stats for iter {iterlist[idx]}: {json.dumps(stats, indent=2)}\")\n",
    "_save_name = f\"single_{use_dataset}_{bsize}_{lr}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  4  6  8 10 12 14 16]\n"
     ]
    }
   ],
   "source": [
    "intervalrange = np.arange(2, 17, 2)\n",
    "print(intervalrange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "& 3.272 & 4.891 & 6.228 & 7.411 & 8.495 & 9.494 & 10.404 & 11.241 \\\\\n",
      "& 0.109 & 0.202 & 0.290 & 0.377 & 0.447 & 0.509 & 0.592 & 0.663 \\\\\n"
     ]
    }
   ],
   "source": [
    "\n",
    "l2listfloats = [num for idx, num in enumerate(totablel2) if idx in intervalrange]\n",
    "lilistfloats = [num for idx, num in enumerate(totableli) if idx in intervalrange]\n",
    "\n",
    "l2str = \"\"\n",
    "for val in l2listfloats:\n",
    "    l2str += f\"& {val:.3f} \" \n",
    "print(l2str  + \"\\\\\\\\\")\n",
    "    \n",
    "listr = \"\"\n",
    "for val in lilistfloats:\n",
    "    listr += f\"& {val:.3f} \" \n",
    "print(listr + \"\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open((save_loc + \"/\" + _save_name + \".json\"), 'w') as f:\n",
    "    json.dump(statlist, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if save_data:\n",
    "#     for name, dream_img in dreams_to_save.items():\n",
    "#         with open(name + \".jpeg\", 'wb') as f:\n",
    "#             # dream_img.save(fp=f , format=\"bmp\", resolution=50)\n",
    "#             dream_img.save(fp=f , format=\"jpeg\", quality=100)\n",
    "\n",
    "\n",
    "# display(dreams[0.01][0][8])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6bbff785f7dca992236909a4969e32f59102c4fceccb1043997c81bace8c71c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
