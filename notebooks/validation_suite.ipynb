{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import torchmetrics\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import foolbox as fb\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch\n",
    "from torch import nn\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "#Make sure of deterministic behaviour\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "\n",
    "\n",
    "from utils import rescale\n",
    "from DataSet.lightning_cifar import CIFARDataModule\n",
    "from models.cifar_nn import Cifar_nn\n",
    "from lightning_trainer import LitModelTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set hyperparameter / global variables\n",
    "\n",
    "# Data location variables:\n",
    "cifar_loc = '../../data'\n",
    "mnist_loc = '../../data/mnist'\n",
    "# val_model_loc = 'trained_models/mnist_base/lightning_logs/version_0/checkpoints/model-epoch=06.ckpt'\n",
    "# val_model_loc = 'trained_models/mnist_adv_livdream_eps05_lr1e5_extrDream_1model/lightning_logs/version_1/checkpoints/model-epoch=05.ckpt'\n",
    "val_model_loc = 'trained_models/BasicNet-PGD-dreams-eps-003/lightning_logs/version_0/checkpoints/model-epoch=20.ckpt'\n",
    "# val_model_loc = 'trained_models/BasicNet-PGD-normal-eps-003/lightning_logs/version_0/checkpoints/model-epoch=16.ckpt'\n",
    "# val_model_loc = 'trained_models/BasicNet-PGD-normal-eps-001/lightning_logs/version_2/checkpoints/model-epoch=39.ckpt'\n",
    "# val_model_loc = 'trained_models/BasicNet-normal/lightning_logs/version_0/checkpoints/model-epoch=49.ckpt' \n",
    "\n",
    "# val_MNIST_adv_eps05_lr1e5_livedreams\n",
    "model_identifier = \"val_CIFAR_dreamAdv_eps003_v0_best_epoch_20\"\n",
    "\n",
    "# Device settings:\n",
    "torch_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "\n",
    "\n",
    "# Transform for data:\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Dataloader\n",
    "batch_size = 250    # Num images per batch\n",
    "num_procs = 1       # Number of workers to fetch data\n",
    "\n",
    "# L2_eps_multiplier = 15      # L2 norm requires a much larger epsilon value as \"budget\" to work with. MNIST.\n",
    "L2_eps_multiplier = 15      # L2 norm requires a much larger epsilon value as \"budget\" to work with. CIFAR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load validation data:\n",
    "# Shuffling data is not necessary for validation runs btw.\n",
    "\n",
    "# classes_list = list(range(10)) # Just numbers for MNIST\n",
    "classes_list = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"]\n",
    "\n",
    "# val_data = MNIST(root=mnist_loc, train=False, download=True, transform=transform)\n",
    "val_data = CIFAR10(root=cifar_loc, train=False, download=True, transform=transform)\n",
    "# val_subset = torch.utils.data.Subset(val_data, list(range(500)))\n",
    "\n",
    "\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, num_workers=num_procs, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from checkpoint:\n",
    "\n",
    "ModelCheckpoint = LitModelTrainer.load_from_checkpoint(val_model_loc)\n",
    "val_model : nn.Module = ModelCheckpoint.model\n",
    "\n",
    "val_model = val_model.to(torch_device)\n",
    "\n",
    "val_model.eval()\n",
    "\n",
    "# Setup model in FB for attacks\n",
    "fmodel = fb.models.pytorch.PyTorchModel(model=val_model, bounds=(0, 1), device=torch_device)\n",
    "\n",
    "# Criterion to use for model loss calculation (not for training!)\n",
    "model_crit = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "\n",
    "# SummaryWriter for metric info and saved images:\n",
    "logging_Obj = SummaryWriter(log_dir=\"validation_results_best/\" + model_identifier, comment='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pairs of string identifiers with (attack, metric provider function) to test\n",
    "# \n",
    "val_attacks = {\n",
    "    \"FGSMrandomstart\": fb.attacks.FGSM(random_start=True),\n",
    "    \"FGSMnorandomstart\": fb.attacks.FGSM(random_start=False),\n",
    "    \"FGSM_L2_randomstart\": fb.attacks.L2FastGradientAttack(random_start=True),\n",
    "    \"FGSM_L2_norandomstart\": fb.attacks.L2FastGradientAttack(random_start=False),\n",
    "    \"PGD_10its_absstepsize1\": fb.attacks.LinfAdamPGD(steps=10, abs_stepsize=1),\n",
    "    \"PGD_21its_absstepsize02\": fb.attacks.LinfAdamPGD(steps=21, abs_stepsize=0.2),\n",
    "    \"PGD_7its_absstepsize2\": fb.attacks.LinfAdamPGD(steps=7, abs_stepsize=2),\n",
    "    \"PGD_15_default\": fb.attacks.LinfAdamPGD(steps=15),\n",
    "\n",
    "    \"CW_reduced_epsilons_L2_const1e-3\": fb.attacks.carlini_wagner.L2CarliniWagnerAttack(steps=12, stepsize=2, abort_early=False, binary_search_steps=1, initial_const=1e-3),\n",
    "    \"CW_reduced_epsilons_L2_const1e-1\": fb.attacks.carlini_wagner.L2CarliniWagnerAttack(steps=12, stepsize=2, abort_early=False, binary_search_steps=1, initial_const=1e-1),\n",
    "    \"CW_reduced_epsilons_L2_const1\": fb.attacks.carlini_wagner.L2CarliniWagnerAttack(steps=12, stepsize=2, abort_early=False, binary_search_steps=1, initial_const=1)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# reduced_epsilons = [0.3, 0.5, 0.7]  # Smaller epsilon set for large attacks - MNIST\n",
    "reduced_epsilons = [0.03, 0.1, 0.3, 0.5]  # Smaller epsilon set for large attacks - CIFAR\n",
    "\n",
    "# Criterion to use (targeted vs untargeted) for attacks\n",
    "adv_crit = fb.criteria.Misclassification\n",
    "\n",
    "# Metrics to calculate/use. In identifier: (metric, reduction method)\n",
    "# Supported reductions: sum, mean, ?conf.matrix?, avgdiff - > Calculates average distance of items in tensors\n",
    "metricsPerAttack = {\n",
    "    \"Loss\" :  (lambda : torchmetrics.MeanMetric().to(device=torch_device), \"\"),\n",
    "    \"Average_perturbation\" : (lambda : torchmetrics.MeanMetric().to(device=torch_device), \"\"),\n",
    "    \"Top_1_Accuracy\" : (lambda : torchmetrics.Accuracy(top_k=1).to(device=torch_device), \"\"),\n",
    "    \"Top_3_Accuracy\" : (lambda : torchmetrics.Accuracy(top_k=3), \"\"), \n",
    "    \"Confusion_Matrix\" : (lambda : torchmetrics.ConfusionMatrix(num_classes=10), \"\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, eps = \"\", att_id = \"\", class_names = list(range(10)), top_1_acc=0.0):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "       cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "       class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "    \n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    \n",
    "    # Normalize the confusion matrix.\n",
    "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "    \n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "    \n",
    "    plt.text(0, -1.5, f'attack_id: {att_id}; eps:{eps}; acc: {top_1_acc:.3f}',\n",
    "        horizontalalignment='center',\n",
    "        verticalalignment='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close()\n",
    "    buf.seek(0)\n",
    "    return buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation funct.\n",
    "def validate_attacks():\n",
    "    attack_num_handled = 0\n",
    "    metric_val_dict = {}\n",
    "\n",
    "    for attack_idx, attack_tuple  in enumerate(val_attacks.items()):\n",
    "        attack_id, val_attack = attack_tuple\n",
    "        if \"_L2\" in attack_id:\n",
    "            epsilon_mult = L2_eps_multiplier\n",
    "        else:\n",
    "            epsilon_mult = 1\n",
    "\n",
    "        if \"reduced_epsilons\" in attack_id:\n",
    "            epsilon_set = reduced_epsilons\n",
    "        else:\n",
    "            epsilon_set = epsilons\n",
    "\n",
    "\n",
    "        print(\"Doing val of \" + attack_id + \", attack step# = \", attack_num_handled)\n",
    "        metric_val_dict[attack_id] = {}\n",
    "        metric_dict = {}\n",
    "        for step, batch in enumerate(val_loader):\n",
    "            x:torch.Tensor\n",
    "            y:torch.Tensor\n",
    "            x, y = batch\n",
    "            x, y = x.to(torch_device), y.to(torch_device)\n",
    "            raw_advs, clipped_advs, success = val_attack(fmodel, x, epsilons=np.multiply(epsilon_set, epsilon_mult), criterion=adv_crit(y))\n",
    "\n",
    "            for eps_idx, epsilon_val in enumerate(epsilon_set):\n",
    "                    \n",
    "\n",
    "                # Setup if on first step of per epsilon\n",
    "                if step == 0:\n",
    "                    metric_dict[str(epsilon_val)] = {}\n",
    "                    metric_val_dict[attack_id][str(epsilon_val)] = {}\n",
    "                x_adv = clipped_advs[eps_idx].to(torch_device)\n",
    "\n",
    "                with torch.no_grad():      # Do forward pass\n",
    "                    y_hat_adv = val_model(x_adv)\n",
    "                    y_hat_adv.to(torch_device)\n",
    "                    y.to(torch_device)\n",
    "\n",
    "                   \n",
    "                    for metric_id, metric in metricsPerAttack.items():\n",
    "                        metric_func: torchmetrics.Metric\n",
    "                        metric_func, metric_reduction = metric\n",
    "                        if step == 0:\n",
    "                            # metric_val_dict[attack_id][str(epsilon_val)][metric_id] = {}\n",
    "                            metric_dict[str(epsilon_val)][metric_id] = metric_func()\n",
    "\n",
    "                        if metric_id == \"Average_perturbation\": # Calculate avg perturbation size on all images\n",
    "                            alldiffstensor = torch.sub(x, x_adv).to(torch_device)\n",
    "                            allmin, allmax = torch.aminmax(dim=0, input=alldiffstensor)\n",
    "                            allmin, allmax = allmin.to(torch_device), allmax.to(torch_device)\n",
    "                            metric_dict[str(epsilon_val)][metric_id](torch.sub(allmax, allmin))\n",
    "\n",
    "                        elif metric_id == \"Loss\":  # Calculate model loss with model criterion\n",
    "                            lossval = model_crit(y_hat_adv, y)\n",
    "                            metric_dict[str(epsilon_val)][metric_id](lossval)\n",
    "                        else:\n",
    "                            metric_dict[str(epsilon_val)][metric_id](y_hat_adv, y)\n",
    "\n",
    "                    #  We want to log the first image of the first batch for each attack, with it's details on perturbation etc.\n",
    "                    if step == 0:\n",
    "                        log_step = 10 * attack_idx + eps_idx\n",
    "                        logging_Obj.add_image(tag=f\"original\", img_tensor=x[0], global_step=log_step)\n",
    "                        logging_Obj.add_image(tag=f\"adv_eps{epsilon_val:.3f}\", img_tensor=x_adv[0], global_step=log_step)\n",
    "\n",
    "                        diff_tensor = torch.sub(x[0], x_adv[0])\n",
    "                        logging_Obj.add_image(tag=f\"diff_eps{epsilon_val:.3f}\", img_tensor=rescale(diff_tensor), global_step=log_step)\n",
    "                        min_val, max_val = torch.aminmax(diff_tensor)\n",
    "                        perturb_size = max_val.item() - min_val.item()\n",
    "                        # print(f\"_pertsize_of_eps{epsilon_val:.3f} is {perturb_size}\")\n",
    "                        logging_Obj.add_scalar(tag=f\"pertsize_of_eps{epsilon_val:.3f}\", scalar_value=perturb_size, global_step=log_step)\n",
    "\n",
    "\n",
    "        # Compound metrics for this validation attack vector\n",
    "        epsilon_num = 0\n",
    "        for epsilon_val_str, metric_pair in metric_dict.items():\n",
    "            metric_num = 0\n",
    "            metric_f: torchmetrics.Metric\n",
    "            for metric_id, metric_f in metric_pair.items():\n",
    "                metric_step = 100 * attack_num_handled + 10 * epsilon_num + metric_num\n",
    "                if metric_id == \"Loss\":\n",
    "                    metric_value = metric_f.compute()\n",
    "                    metric_val_dict[attack_id][epsilon_val_str][metric_id] = metric_value\n",
    "                    logging_Obj.add_scalar(tag=metric_id, scalar_value=metric_value, global_step=metric_step)\n",
    "                elif metric_id == \"Confusion_Matrix\":\n",
    "                    metric_value = metric_f.compute()\n",
    "                   \n",
    "                    cm_buffer = plot_confusion_matrix(cm=metric_value.detach().cpu().numpy(), eps=f\"{(float(epsilon_val_str) * epsilon_mult):.3f}\", att_id=attack_id, class_names=classes_list, top_1_acc=metric_val_dict[attack_id][epsilon_val_str][\"Top_1_Accuracy\"])\n",
    "\n",
    "                    cm_img = PIL.Image.open(cm_buffer)\n",
    "                    cm_img = transforms.ToTensor()(cm_img)\n",
    "                    logging_Obj.add_image(tag=metric_id, img_tensor=cm_img, global_step=metric_step)\n",
    "                    metric_val_dict[attack_id][epsilon_val_str][metric_id] = metric_value\n",
    "                    # metric_f.reset()\n",
    "                else:\n",
    "                    metric_value = metric_f.compute()\n",
    "                    logging_Obj.add_scalar(tag=metric_id, scalar_value=metric_value, global_step=metric_step)\n",
    "                    metric_val_dict[attack_id][epsilon_val_str][metric_id] = metric_value\n",
    "                    # metric_f.reset()\n",
    "                metric_num += 1\n",
    "            epsilon_num +=1\n",
    "        attack_num_handled += 1\n",
    "    return metric_val_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing val of FGSMrandomstart, attack step# =  0\n",
      "Doing val of FGSMnorandomstart, attack step# =  1\n",
      "Doing val of FGSM_L2_randomstart, attack step# =  2\n",
      "Doing val of FGSM_L2_norandomstart, attack step# =  3\n",
      "Doing val of PGD_10its_absstepsize1, attack step# =  4\n",
      "Doing val of PGD_21its_absstepsize02, attack step# =  5\n",
      "Doing val of PGD_7its_absstepsize2, attack step# =  6\n",
      "Doing val of PGD_15_default, attack step# =  7\n",
      "Doing val of CW_reduced_epsilons_L2_const1e-3, attack step# =  8\n",
      "Doing val of CW_reduced_epsilons_L2_const1e-1, attack step# =  9\n",
      "Doing val of CW_reduced_epsilons_L2_const1, attack step# =  10\n"
     ]
    }
   ],
   "source": [
    "dict_result = validate_attacks()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric step 0 logs eps 0.005 for metric Loss\n",
      "Metric step 1 logs eps 0.005 for metric Average_perturbation\n",
      "Metric step 2 logs eps 0.005 for metric Top_1_Accuracy\n",
      "Metric step 3 logs eps 0.005 for metric Top_3_Accuracy\n",
      "Metric step 4 logs eps 0.005 for metric Confusion_Matrix\n",
      "Metric step 10 logs eps 0.01 for metric Loss\n",
      "Metric step 11 logs eps 0.01 for metric Average_perturbation\n",
      "Metric step 12 logs eps 0.01 for metric Top_1_Accuracy\n",
      "Metric step 13 logs eps 0.01 for metric Top_3_Accuracy\n",
      "Metric step 14 logs eps 0.01 for metric Confusion_Matrix\n",
      "Metric step 20 logs eps 0.03 for metric Loss\n",
      "Metric step 21 logs eps 0.03 for metric Average_perturbation\n",
      "Metric step 22 logs eps 0.03 for metric Top_1_Accuracy\n",
      "Metric step 23 logs eps 0.03 for metric Top_3_Accuracy\n",
      "Metric step 24 logs eps 0.03 for metric Confusion_Matrix\n",
      "Metric step 30 logs eps 0.1 for metric Loss\n",
      "Metric step 31 logs eps 0.1 for metric Average_perturbation\n",
      "Metric step 32 logs eps 0.1 for metric Top_1_Accuracy\n",
      "Metric step 33 logs eps 0.1 for metric Top_3_Accuracy\n",
      "Metric step 34 logs eps 0.1 for metric Confusion_Matrix\n",
      "Metric step 40 logs eps 0.3 for metric Loss\n",
      "Metric step 41 logs eps 0.3 for metric Average_perturbation\n",
      "Metric step 42 logs eps 0.3 for metric Top_1_Accuracy\n",
      "Metric step 43 logs eps 0.3 for metric Top_3_Accuracy\n",
      "Metric step 44 logs eps 0.3 for metric Confusion_Matrix\n"
     ]
    }
   ],
   "source": [
    "eps_count = 0\n",
    "for epsilon_val in epsilons:\n",
    "    metric_count = 0\n",
    "    for metric_id, _ in metricsPerAttack.items():\n",
    "        print(f\"Metric step {10*eps_count + metric_count} logs eps {str(epsilon_val)} for metric {metric_id}\")\n",
    "        metric_count += 1\n",
    "    eps_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "Attack vector:  FGSMrandomstart\n",
      "With epsilon value: 0.005\n",
      "Metric:  Loss  has value: 0.96792\n",
      "Metric:  Average_perturbation  has value: 0.01000\n",
      "Metric:  Top_1_Accuracy  has value: 0.66200\n",
      "Metric:  Top_3_Accuracy  has value: 0.90080\n",
      "Confusion matrix:\n",
      "With epsilon value: 0.010\n",
      "Metric:  Loss  has value: 1.11347\n",
      "Metric:  Average_perturbation  has value: 0.02000\n",
      "Metric:  Top_1_Accuracy  has value: 0.60970\n",
      "Metric:  Top_3_Accuracy  has value: 0.87200\n",
      "Confusion matrix:\n",
      "With epsilon value: 0.030\n",
      "Metric:  Loss  has value: 1.74084\n",
      "Metric:  Average_perturbation  has value: 0.06000\n",
      "Metric:  Top_1_Accuracy  has value: 0.39410\n",
      "Metric:  Top_3_Accuracy  has value: 0.73950\n",
      "Confusion matrix:\n",
      "With epsilon value: 0.100\n",
      "Metric:  Loss  has value: 4.02633\n",
      "Metric:  Average_perturbation  has value: 0.20000\n",
      "Metric:  Top_1_Accuracy  has value: 0.06960\n",
      "Metric:  Top_3_Accuracy  has value: 0.39170\n",
      "Confusion matrix:\n",
      "With epsilon value: 0.300\n",
      "Metric:  Loss  has value: 8.37462\n",
      "Metric:  Average_perturbation  has value: 0.60000\n",
      "Metric:  Top_1_Accuracy  has value: 0.01830\n",
      "Metric:  Top_3_Accuracy  has value: 0.14260\n",
      "Confusion matrix:\n",
      "Attack vector:  FGSMnorandomstart\n",
      "With epsilon value: 0.005\n",
      "Metric:  Loss  has value: 1.01575\n",
      "Metric:  Average_perturbation  has value: 0.01000\n",
      "Metric:  Top_1_Accuracy  has value: 0.64430\n",
      "Metric:  Top_3_Accuracy  has value: 0.89230\n",
      "Confusion matrix:\n",
      "With epsilon value: 0.010\n",
      "Metric:  Loss  has value: 1.21379\n",
      "Metric:  Average_perturbation  has value: 0.02000\n",
      "Metric:  Top_1_Accuracy  has value: 0.56850\n",
      "Metric:  Top_3_Accuracy  has value: 0.85200\n",
      "Confusion matrix:\n",
      "With epsilon value: 0.030\n",
      "Metric:  Loss  has value: 2.07363\n",
      "Metric:  Average_perturbation  has value: 0.06000\n",
      "Metric:  Top_1_Accuracy  has value: 0.31330\n",
      "Metric:  Top_3_Accuracy  has value: 0.67860\n",
      "Confusion matrix:\n",
      "With epsilon value: 0.100\n",
      "Metric:  Loss  has value: 4.56653\n",
      "Metric:  Average_perturbation  has value: 0.20000\n",
      "Metric:  Top_1_Accuracy  has value: 0.04810\n",
      "Metric:  Top_3_Accuracy  has value: 0.33740\n",
      "Confusion matrix:\n",
      "With epsilon value: 0.300\n",
      "Metric:  Loss  has value: 6.18373\n",
      "Metric:  Average_perturbation  has value: 0.60000\n",
      "Metric:  Top_1_Accuracy  has value: 0.07850\n",
      "Metric:  Top_3_Accuracy  has value: 0.25590\n",
      "Confusion matrix:\n",
      "Attack vector:  FGSM_L2_randomstart\n",
      "With epsilon value: 0.075\n",
      "Metric:  Loss  has value: 0.89281\n",
      "Metric:  Average_perturbation  has value: 0.00839\n",
      "Metric:  Top_1_Accuracy  has value: 0.69360\n",
      "Metric:  Top_3_Accuracy  has value: 0.91660\n",
      "Confusion matrix:\n",
      "With epsilon value: 0.150\n",
      "Metric:  Loss  has value: 0.95815\n",
      "Metric:  Average_perturbation  has value: 0.01678\n",
      "Metric:  Top_1_Accuracy  has value: 0.66600\n",
      "Metric:  Top_3_Accuracy  has value: 0.90380\n",
      "Confusion matrix:\n",
      "With epsilon value: 0.450\n",
      "Metric:  Loss  has value: 1.23427\n",
      "Metric:  Average_perturbation  has value: 0.05030\n",
      "Metric:  Top_1_Accuracy  has value: 0.55880\n",
      "Metric:  Top_3_Accuracy  has value: 0.85060\n",
      "Confusion matrix:\n",
      "With epsilon value: 1.500\n",
      "Metric:  Loss  has value: 2.27451\n",
      "Metric:  Average_perturbation  has value: 0.16714\n",
      "Metric:  Top_1_Accuracy  has value: 0.26360\n",
      "Metric:  Top_3_Accuracy  has value: 0.65310\n",
      "Confusion matrix:\n",
      "With epsilon value: 4.500\n",
      "Metric:  Loss  has value: 4.81040\n",
      "Metric:  Average_perturbation  has value: 0.48613\n",
      "Metric:  Top_1_Accuracy  has value: 0.05620\n",
      "Metric:  Top_3_Accuracy  has value: 0.34030\n",
      "Confusion matrix:\n",
      "Attack vector:  FGSM_L2_norandomstart\n",
      "With epsilon value: 0.075\n",
      "Metric:  Loss  has value: 0.91953\n",
      "Metric:  Average_perturbation  has value: 0.00864\n",
      "Metric:  Top_1_Accuracy  has value: 0.68230\n",
      "Metric:  Top_3_Accuracy  has value: 0.91180\n",
      "Confusion matrix:\n",
      "With epsilon value: 0.150\n",
      "Metric:  Loss  has value: 1.01316\n",
      "Metric:  Average_perturbation  has value: 0.01727\n",
      "Metric:  Top_1_Accuracy  has value: 0.64470\n",
      "Metric:  Top_3_Accuracy  has value: 0.89420\n",
      "Confusion matrix:\n",
      "With epsilon value: 0.450\n",
      "Metric:  Loss  has value: 1.41104\n",
      "Metric:  Average_perturbation  has value: 0.05179\n",
      "Metric:  Top_1_Accuracy  has value: 0.49610\n",
      "Metric:  Top_3_Accuracy  has value: 0.81320\n",
      "Confusion matrix:\n",
      "With epsilon value: 1.500\n",
      "Metric:  Loss  has value: 2.81392\n",
      "Metric:  Average_perturbation  has value: 0.17179\n",
      "Metric:  Top_1_Accuracy  has value: 0.17980\n",
      "Metric:  Top_3_Accuracy  has value: 0.57010\n",
      "Confusion matrix:\n",
      "With epsilon value: 4.500\n",
      "Metric:  Loss  has value: 4.77449\n",
      "Metric:  Average_perturbation  has value: 0.48112\n",
      "Metric:  Top_1_Accuracy  has value: 0.09040\n",
      "Metric:  Top_3_Accuracy  has value: 0.37070\n",
      "Confusion matrix:\n",
      "Attack vector:  PGD_10its_absstepsize1\n",
      "With epsilon value: 0.005\n",
      "Metric:  Loss  has value: 1.02124\n",
      "Metric:  Average_perturbation  has value: 0.01000\n",
      "Metric:  Top_1_Accuracy  has value: 0.64280\n",
      "Metric:  Top_3_Accuracy  has value: 0.89120\n",
      "Confusion matrix:\n",
      "With epsilon value: 0.010\n",
      "Metric:  Loss  has value: 1.23000\n",
      "Metric:  Average_perturbation  has value: 0.02000\n",
      "Metric:  Top_1_Accuracy  has value: 0.56390\n",
      "Metric:  Top_3_Accuracy  has value: 0.84940\n",
      "Confusion matrix:\n",
      "With epsilon value: 0.030\n",
      "Metric:  Loss  has value: 2.13258\n",
      "Metric:  Average_perturbation  has value: 0.06000\n",
      "Metric:  Top_1_Accuracy  has value: 0.30040\n",
      "Metric:  Top_3_Accuracy  has value: 0.68010\n",
      "Confusion matrix:\n",
      "With epsilon value: 0.100\n",
      "Metric:  Loss  has value: 5.68745\n",
      "Metric:  Average_perturbation  has value: 0.20000\n",
      "Metric:  Top_1_Accuracy  has value: 0.06300\n",
      "Metric:  Top_3_Accuracy  has value: 0.38470\n",
      "Confusion matrix:\n",
      "With epsilon value: 0.300\n",
      "Metric:  Loss  has value: 12.25125\n",
      "Metric:  Average_perturbation  has value: 0.60000\n",
      "Metric:  Top_1_Accuracy  has value: 0.00790\n",
      "Metric:  Top_3_Accuracy  has value: 0.17700\n",
      "Confusion matrix:\n",
      "Attack vector:  PGD_21its_absstepsize02\n",
      "With epsilon value: 0.005\n",
      "Metric:  Loss  has value: 1.02143\n",
      "Metric:  Average_perturbation  has value: 0.01000\n",
      "Metric:  Top_1_Accuracy  has value: 0.64280\n",
      "Metric:  Top_3_Accuracy  has value: 0.89080\n",
      "Confusion matrix:\n",
      "With epsilon value: 0.010\n",
      "Metric:  Loss  has value: 1.23131\n",
      "Metric:  Average_perturbation  has value: 0.02000\n",
      "Metric:  Top_1_Accuracy  has value: 0.56230\n",
      "Metric:  Top_3_Accuracy  has value: 0.84890\n",
      "Confusion matrix:\n",
      "With epsilon value: 0.030\n",
      "Metric:  Loss  has value: 2.16387\n",
      "Metric:  Average_perturbation  has value: 0.06000\n",
      "Metric:  Top_1_Accuracy  has value: 0.29510\n",
      "Metric:  Top_3_Accuracy  has value: 0.66920\n",
      "Confusion matrix:\n",
      "With epsilon value: 0.100\n",
      "Metric:  Loss  has value: 6.36207\n",
      "Metric:  Average_perturbation  has value: 0.20000\n",
      "Metric:  Top_1_Accuracy  has value: 0.03360\n",
      "Metric:  Top_3_Accuracy  has value: 0.28990\n",
      "Confusion matrix:\n",
      "With epsilon value: 0.300\n",
      "Metric:  Loss  has value: 41.63793\n",
      "Metric:  Average_perturbation  has value: 0.60000\n",
      "Metric:  Top_1_Accuracy  has value: 0.00000\n",
      "Metric:  Top_3_Accuracy  has value: 0.04080\n",
      "Confusion matrix:\n",
      "Attack vector:  PGD_7its_absstepsize2\n",
      "With epsilon value: 0.005\n",
      "Metric:  Loss  has value: 1.02163\n",
      "Metric:  Average_perturbation  has value: 0.01000\n",
      "Metric:  Top_1_Accuracy  has value: 0.64220\n",
      "Metric:  Top_3_Accuracy  has value: 0.89090\n",
      "Confusion matrix:\n",
      "With epsilon value: 0.010\n",
      "Metric:  Loss  has value: 1.23324\n",
      "Metric:  Average_perturbation  has value: 0.02000\n",
      "Metric:  Top_1_Accuracy  has value: 0.56220\n",
      "Metric:  Top_3_Accuracy  has value: 0.84870\n",
      "Confusion matrix:\n",
      "With epsilon value: 0.030\n",
      "Metric:  Loss  has value: 2.19221\n",
      "Metric:  Average_perturbation  has value: 0.06000\n",
      "Metric:  Top_1_Accuracy  has value: 0.29310\n",
      "Metric:  Top_3_Accuracy  has value: 0.66230\n",
      "Confusion matrix:\n",
      "With epsilon value: 0.100\n",
      "Metric:  Loss  has value: 6.36088\n",
      "Metric:  Average_perturbation  has value: 0.20000\n",
      "Metric:  Top_1_Accuracy  has value: 0.03230\n",
      "Metric:  Top_3_Accuracy  has value: 0.27020\n",
      "Confusion matrix:\n",
      "With epsilon value: 0.300\n",
      "Metric:  Loss  has value: 13.01299\n",
      "Metric:  Average_perturbation  has value: 0.60000\n",
      "Metric:  Top_1_Accuracy  has value: 0.00730\n",
      "Metric:  Top_3_Accuracy  has value: 0.09320\n",
      "Confusion matrix:\n",
      "Attack vector:  PGD_15_default\n",
      "With epsilon value: 0.005\n",
      "Metric:  Loss  has value: 0.91060\n",
      "Metric:  Average_perturbation  has value: 0.01000\n",
      "Metric:  Top_1_Accuracy  has value: 0.68700\n",
      "Metric:  Top_3_Accuracy  has value: 0.91260\n",
      "Confusion matrix:\n",
      "With epsilon value: 0.010\n",
      "Metric:  Loss  has value: 0.99718\n",
      "Metric:  Average_perturbation  has value: 0.02000\n",
      "Metric:  Top_1_Accuracy  has value: 0.65130\n",
      "Metric:  Top_3_Accuracy  has value: 0.89590\n",
      "Confusion matrix:\n",
      "With epsilon value: 0.030\n",
      "Metric:  Loss  has value: 1.40177\n",
      "Metric:  Average_perturbation  has value: 0.06000\n",
      "Metric:  Top_1_Accuracy  has value: 0.50430\n",
      "Metric:  Top_3_Accuracy  has value: 0.81050\n",
      "Confusion matrix:\n",
      "With epsilon value: 0.100\n",
      "Metric:  Loss  has value: 3.79570\n",
      "Metric:  Average_perturbation  has value: 0.20000\n",
      "Metric:  Top_1_Accuracy  has value: 0.10440\n",
      "Metric:  Top_3_Accuracy  has value: 0.43580\n",
      "Confusion matrix:\n",
      "With epsilon value: 0.300\n",
      "Metric:  Loss  has value: 16.98150\n",
      "Metric:  Average_perturbation  has value: 0.60000\n",
      "Metric:  Top_1_Accuracy  has value: 0.00010\n",
      "Metric:  Top_3_Accuracy  has value: 0.05120\n",
      "Confusion matrix:\n",
      "Attack vector:  CW_reduced_epsilons_L2_const1e-3\n",
      "With epsilon value: 0.450\n",
      "Metric:  Loss  has value: 0.95247\n",
      "Metric:  Average_perturbation  has value: 0.02905\n",
      "Metric:  Top_1_Accuracy  has value: 0.58100\n",
      "Metric:  Top_3_Accuracy  has value: 0.92470\n",
      "Confusion matrix:\n",
      "With epsilon value: 1.500\n",
      "Metric:  Loss  has value: 1.33406\n",
      "Metric:  Average_perturbation  has value: 0.09684\n",
      "Metric:  Top_1_Accuracy  has value: 0.33380\n",
      "Metric:  Top_3_Accuracy  has value: 0.87650\n",
      "Confusion matrix:\n",
      "With epsilon value: 4.500\n",
      "Metric:  Loss  has value: 2.66999\n",
      "Metric:  Average_perturbation  has value: 0.29030\n",
      "Metric:  Top_1_Accuracy  has value: 0.09150\n",
      "Metric:  Top_3_Accuracy  has value: 0.69150\n",
      "Confusion matrix:\n",
      "With epsilon value: 7.500\n",
      "Metric:  Loss  has value: 3.43503\n",
      "Metric:  Average_perturbation  has value: 0.47404\n",
      "Metric:  Top_1_Accuracy  has value: 0.05710\n",
      "Metric:  Top_3_Accuracy  has value: 0.57860\n",
      "Confusion matrix:\n",
      "Attack vector:  CW_reduced_epsilons_L2_const1e-1\n",
      "With epsilon value: 0.450\n",
      "Metric:  Loss  has value: 0.95453\n",
      "Metric:  Average_perturbation  has value: 0.02918\n",
      "Metric:  Top_1_Accuracy  has value: 0.57950\n",
      "Metric:  Top_3_Accuracy  has value: 0.92480\n",
      "Confusion matrix:\n",
      "With epsilon value: 1.500\n",
      "Metric:  Loss  has value: 1.36057\n",
      "Metric:  Average_perturbation  has value: 0.09727\n",
      "Metric:  Top_1_Accuracy  has value: 0.33600\n",
      "Metric:  Top_3_Accuracy  has value: 0.87240\n",
      "Confusion matrix:\n",
      "With epsilon value: 4.500\n",
      "Metric:  Loss  has value: 2.73624\n",
      "Metric:  Average_perturbation  has value: 0.29167\n",
      "Metric:  Top_1_Accuracy  has value: 0.11670\n",
      "Metric:  Top_3_Accuracy  has value: 0.68930\n",
      "Confusion matrix:\n",
      "With epsilon value: 7.500\n",
      "Metric:  Loss  has value: 3.47347\n",
      "Metric:  Average_perturbation  has value: 0.48339\n",
      "Metric:  Top_1_Accuracy  has value: 0.08360\n",
      "Metric:  Top_3_Accuracy  has value: 0.59280\n",
      "Confusion matrix:\n",
      "Attack vector:  CW_reduced_epsilons_L2_const1\n",
      "With epsilon value: 0.450\n",
      "Metric:  Loss  has value: 0.84677\n",
      "Metric:  Average_perturbation  has value: 0.03435\n",
      "Metric:  Top_1_Accuracy  has value: 0.70190\n",
      "Metric:  Top_3_Accuracy  has value: 0.92850\n",
      "Confusion matrix:\n",
      "With epsilon value: 1.500\n",
      "Metric:  Loss  has value: 0.90179\n",
      "Metric:  Average_perturbation  has value: 0.11449\n",
      "Metric:  Top_1_Accuracy  has value: 0.65340\n",
      "Metric:  Top_3_Accuracy  has value: 0.92620\n",
      "Confusion matrix:\n",
      "With epsilon value: 4.500\n",
      "Metric:  Loss  has value: 1.13431\n",
      "Metric:  Average_perturbation  has value: 0.34337\n",
      "Metric:  Top_1_Accuracy  has value: 0.51340\n",
      "Metric:  Top_3_Accuracy  has value: 0.90620\n",
      "Confusion matrix:\n",
      "With epsilon value: 7.500\n",
      "Metric:  Loss  has value: 1.43388\n",
      "Metric:  Average_perturbation  has value: 0.57105\n",
      "Metric:  Top_1_Accuracy  has value: 0.39390\n",
      "Metric:  Top_3_Accuracy  has value: 0.86880\n",
      "Confusion matrix:\n"
     ]
    }
   ],
   "source": [
    "print(\"Results:\")\n",
    "\n",
    "for attack_id, att in val_attacks.items():\n",
    "    print(\"Attack vector: \" , attack_id)\n",
    "    if \"reduced_epsilons\" in attack_id:\n",
    "        epsilon_set = reduced_epsilons\n",
    "    else:\n",
    "        epsilon_set = epsilons\n",
    "    for eps in epsilon_set:\n",
    "        eps_mult = 1\n",
    "        if \"_L2\" in attack_id:\n",
    "            eps_mult = L2_eps_multiplier\n",
    "\n",
    "        print(f\"With epsilon value: {eps * eps_mult:.3f}\")\n",
    "        for metric_id, metric_val in metricsPerAttack.items():\n",
    "            metric_val = dict_result[attack_id][str(eps)][metric_id].detach().cpu().numpy()\n",
    "            if metric_id == \"Confusion_Matrix\":\n",
    "                print(\"Confusion matrix:\")\n",
    "                plot_confusion_matrix(metric_val, eps=f\"{eps * eps_mult:.3f}\", att_id = attack_id)\n",
    "            else:\n",
    "                print(\"Metric: \", metric_id, f\" has value: {metric_val:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('validation_results/' + model_identifier + '.txt', 'w') as f:\n",
    "    print(dict_result, file=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d4ed44c6a2a13ca6ab9393ffa30cf54197e027a07f139da5103fcdd4e6439bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
